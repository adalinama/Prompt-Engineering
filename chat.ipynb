{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1028 entries, 0 to 1027\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review_id  1028 non-null   object\n",
      " 1   text       1028 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 16.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pandadata = pd.read_csv('data/review_sample.csv')\n",
    "pandadata = pandadata.drop('Unnamed: 0', axis=1)\n",
    "pandadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/tracypham/anaconda3/lib/python3.10/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Set env var OPENAI_API_KEY or load from a .env file:\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我喜欢编程。 (Wǒ xǐhuān biānchéng.)', response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 19, 'total_tokens': 43}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_ad2b9c6e11', 'finish_reason': 'stop', 'logprobs': None}, id='run-b1358268-d92e-4d36-b418-3dec04488c80-0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "chat.invoke(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"Translate this sentence from English to Chinese: I love programming.\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm an AI digital assistant, so I don't speak. I communicate through text. How can I assist you today?\", response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 13, 'total_tokens': 38}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_ad2b9c6e11', 'finish_reason': 'stop', 'logprobs': None}, id='run-4ebc5075-bc03-4e33-be66-682567b7123c-0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No concept of state:\n",
    "chat.invoke([HumanMessage(content=\"What did you just say?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said \"我喜欢编程\" which means \"I love programming\" in Chinese.', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 57, 'total_tokens': 78}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_ad2b9c6e11', 'finish_reason': 'stop', 'logprobs': None}, id='run-d1f96396-d7fd-4feb-8307-c64c0c1db121-0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "chat.invoke(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"Translate this sentence from English to Chinese: I love programming.\"\n",
    "        ),\n",
    "        AIMessage(content='我喜欢编程。 (Wǒ xǐhuān biānchéng.)'),\n",
    "        HumanMessage(content=\"What did you just say?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define prompt template to make formatting easier, create a chain by piping it into the model\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said \"我喜欢编程\" (Wǒ xǐhuān biānchéng), which means \"I love programming\" in Chinese.', response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 77, 'total_tokens': 114}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_ad2b9c6e11', 'finish_reason': 'stop', 'logprobs': None}, id='run-081d5905-ff91-4023-953a-937564979fdd-0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Translate this sentence from English to Chinese: I love programming.\"\n",
    "            ),\n",
    "            AIMessage(content='我喜欢编程。 (Wǒ xǐhuān biānchéng.)'),\n",
    "            HumanMessage(content=\"What did you just say?\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!'), AIMessage(content='whats up?')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in-memory demo message history \n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "demo_ephemeral_chat_history = ChatMessageHistory()\n",
    "\n",
    "demo_ephemeral_chat_history.add_user_message(\"hi!\")\n",
    "\n",
    "demo_ephemeral_chat_history.add_ai_message(\"whats up?\")\n",
    "\n",
    "demo_ephemeral_chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The translation of \"I love programming\" in French is \"J\\'adore la programmation.\"', response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 53, 'total_tokens': 73}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_77a673219d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2bb1f7b0-fc67-4c1f-968e-6ff793273b2e-0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_user_message(\n",
    "    \"Translate this sentence from English to French: I love programming.\"\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"messages\": demo_ephemeral_chat_history.messages})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said, \"J\\'adore la programmation,\" which means \"I love programming\" in French.', response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 87, 'total_tokens': 109}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_ad2b9c6e11', 'finish_reason': 'stop', 'logprobs': None}, id='run-4ea8cd0f-fdcd-467f-a1f3-f6ba21c95b7e-0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_ai_message(response)\n",
    "\n",
    "demo_ephemeral_chat_history.add_user_message(\"What did you just say?\")\n",
    "\n",
    "chain.invoke({\"messages\": demo_ephemeral_chat_history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "\n",
    "loader = CSVLoader(file_path='./data/review_sample.csv')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /Users/tracypham/anaconda3/lib/python3.10/site-packages (1.8.0)\r\n",
      "Requirement already satisfied: numpy in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from faiss-cpu) (1.23.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (634265509.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[60], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    texts = te xt_splitter.split_documents(documents)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# db vectorstore retriever\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = te xt_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "retriever = db.as_retriever(k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# split into smaller chunks so context window can store in vector database\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /Users/tracypham/anaconda3/lib/python3.10/site-packages (0.4.24)\n",
      "Requirement already satisfied: importlib-resources in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (6.4.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (3.5.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (1.62.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: requests>=2.28 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (2.6.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (4.9.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (0.12.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (0.110.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (6.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (4.1.2)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (0.29.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (1.17.3)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (0.19.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (1.23.5)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (29.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (3.10.0)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (4.66.2)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from chromadb) (3.5.0)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Requirement already satisfied: packaging>=19.1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2023.11.17)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.28.1)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.14)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: coloredlogs in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: protobuf in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: flatbuffers in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.6)\n",
      "Requirement already satisfied: sympy in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
      "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.45b0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (65.6.3)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asgiref~=3.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.16.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.22.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.17.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (3.5.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/tracypham/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->onnxruntime>=1.14.1->chromadb) (1.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# embed and store chunks in vector database\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=': 219\\nreview_id: tvX9owIjsyCTMOVBL_ucgQ\\ntext: Loved this place. We were on a hunt for the best milkshake in New Orleans back in May and The Camellia Grill did not disappoint. We tried the cherry and orange freezes and both were delish!  The onion rings were also quite good. Our waiter Marvin was personable and quick. It was an all-around great experience. \\n\\n(Quick note to say: riding high on that milkshake buzz, we took our friends who were not with us to the location near the French Quarter so they could try the shakes. We had the worst service in the history of service there, including a waiter who was so drunk we thought he was going to get sick right in front of us. So definitely stick with the this location!)', metadata={'source': './data/review_sample.csv', 'row': 219}),\n",
       " Document(page_content=\"We got two friezes (milkshakes), the chocolate and coffee frieze.  Liked both, although I'd go back to try the vanilla double-scoop frieze, especially if I am staying at a hotel with a functioning gym ... only complaint about my coffee frieze was it was very slushy.  Maybe ask to cut down on the ice and double the ice cream (I think they use Blue Bell).\\n\\nTo finish the decadence, we got dessert.  You cannot go to Camellia and NOT order dessert.  Seriously, if you want to make a checklist of what to get when you go, stick with the omelette, maybe a frieze, but definitely a slice of pie.  We shared the vaunted Grilled Pecan Pie (served with a scoop of vanilla ice cream) and Coconut Creme Pie.  I never had coconut creme pie before and shit, it was good.  So good I stole the last bite from my girl friend.  And it was a big bite.\", metadata={'source': './data/review_sample.csv', 'row': 987}),\n",
       " Document(page_content=\": 640\\nreview_id: b9mXKT4KniZ3Y8TH8OXXTg\\ntext: Don't be frightened by the long line outside this joint! Go and stand in line, its worth the wait. Make sure you go with an old friend or some great company, you will have plenty of time to chat and catch up while you wait. \\n\\nOnce we were seated, we were greeted with the most awesome staff I've ever been served by in a breakfast joint. We not only enjoyed our service experience but the food experience was excellent as well. Camellia's omelets are a must order! The eggs are whipped up in one of those milkshake mixers before poured over the griddle. The result is the fluffiest omelets I've ever had! \\n\\nSide note, I thought it was interesting that they make omelets with milkshake mixers and milkshakes with a blender.\", metadata={'source': './data/review_sample.csv', 'row': 640}),\n",
       " Document(page_content=\": 102\\nreview_id: R4D6VSyXxyCU31Pj9geCKQ\\ntext: I would go here just for the chocolate pecan pie! Served warm (they toss it on the grill with some butter) with ice cream....I'm salivating just thinking about it. \\n\\nCamellia Grill is one of those places we HAVE to go to every visit. My husband always orders the Chef's Special omelet, you never know what you'll find in it! It's huge, the sixe of a rolled newspaper. The burgers are fantastic too. \\n\\nThere is usually a line out the door, there are only a few seats inside, but its worth the wait! The waiters are always friendly and make you feel like you are a regular there. So glad they re-opened after Katrina!\", metadata={'source': './data/review_sample.csv', 'row': 102})]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create retriever from our initialized vectorstore\n",
    "# k is the number of chunks to retrieve\n",
    "\n",
    "#retriever = vectorstore.as_retriever(k=4)\n",
    "\n",
    "docs = retriever.invoke(\"What are the best milkshakes at Camellia Grill?\")\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "# modify prompt to accept documents as context\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "question_answering_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user's questions based on the below context:\\n\\n{context}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(chat, question_answering_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Camellia Grill is a popular spot in New Orleans known for its delicious milkshakes, omelets, and pies. The restaurant has a friendly and personable staff, and it's a great place to catch up with friends while waiting in line. Customers rave about the fluffy omelets made in milkshake mixers and the decadent pecan pies served warm with ice cream. Despite occasional long lines, the experience and food are well worth the wait. It's a place that locals and visitors alike love to frequent.\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invode document chain with docs\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "demo_ephemeral_chat_history = ChatMessageHistory()\n",
    "\n",
    "demo_ephemeral_chat_history.add_user_message(\"What can you tell me about the Camellia Grill?\")\n",
    "\n",
    "document_chain.invoke(\n",
    "    {\n",
    "        \"messages\": demo_ephemeral_chat_history.messages,\n",
    "        \"context\": docs,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a retrieval chain\n",
    "# extract last message from user for input to relevant docs, add to current chain as context\n",
    "# pass context plus previous messages into the document chain to generate answer\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def parse_retriever_input(params: Dict):\n",
    "    return params[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "retrieval_chain = RunnablePassthrough.assign(\n",
    "    context=parse_retriever_input | retriever,\n",
    ").assign(\n",
    "    answer=document_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What can you tell me about the Camellia Grill?')],\n",
       " 'context': [Document(page_content=': 989\\nreview_id: PsWZU2dyIpWJZYxfgpqZMg\\ntext: The Camellia Grill is an institution, so much so that they were filming a segment for a TV show/movie on my recent visit (and the fascination surrounding this outweighed the delay in service that happened as a result).\\n\\nHere is what you will find...\\n\\n1. Servers like Michael who take a lot of pride in their work. They call out multiple orders at a time, then the cooks go to work.\\n2. 100% low counter seating. Every seat faces the kitchen. If your larger group wants to have a conversation, this may not be the best place.\\n3. Delicious breakfast options (standard eggs and bacon, grits, omelettes, pancakes), burgers, shakes, etc. Imagine taking the best of Waffle House and Johnny Rockets and putting it into a fun, local establishment.\\n4. It is crowded at peak breakfast and lunch times.', metadata={'source': './data/review_sample.csv', 'row': 989}),\n",
       "  Document(page_content=\": 1026\\nreview_id: UuthR2CkatLYPnUVZMtaTw\\ntext: The Camellia Grill is a legend in New Orleans. Definitely the type of place I bring friends and family to when they come to visit. As locals, me and my family go there every time were in the area.  It's my favorite place to eat because the atmosphere, the service, and the food. When we walk in the door I feel like I'm stepping back in time to an old time diner.  The set-up is just one long counter surrounding the grills and it's decorated like were back in the 50's. The servers wear white dress shirts with bow ties like you expect to see in a diner. It has a vintage feel.  It's the time of place that the waiters call out your order to the back using diner lingo and they are always so friendly. If you don't know what to get they are always open to giving suggestions on classic favorites. They are perfect for late night, early morning, lunch, and dinner. They have breakfast food and a good variety of burgers and sandwiches. The food is cooked right in front of you, however you like it. I would recommend this place to locals and tourist. It's a new Orleans classic.\", metadata={'source': './data/review_sample.csv', 'row': 1026}),\n",
       "  Document(page_content=\": 720\\nreview_id: bd14Qo_l8VJh1-KfTmz7Fg\\ntext: Camellia Grill is the type of diners you see in the movies.  The atmosphere here is an overall good dining experience. I've been here twice, one for lunch and once for dinner. Countertop seating is where it's at here. There was no wait both times I've been there. Quick and attentive service has you in and out of there enjoying their delicious grill options and home-style cooking. Breakfast items are the classic American menu, with bacon, eggs, and more. The burgers were everything I would expect in a good burger. The patties had a nice taste and dressing options for the burger were plenty with fresh vegetables. The fries and onion rings were exceptional. This is a good place for chatting or even reading a book while eating, like I saw some people doing. The staff are familiar with the customers as well. Overall, Camelia's Grill delivers everything one would expect for a diner. This place is definitely a NOLA classic.\", metadata={'source': './data/review_sample.csv', 'row': 720}),\n",
       "  Document(page_content=\": 377\\nreview_id: kR28I_muoQGwF4cO94Fwdw\\ntext: So much to say about Camellia Grill. It may seem like just an old, run-down restaurant, but it is much more than that. Camellia puts out great breakfast food that I will eat at any time of the day, very good burgers and sandwiches, and excellent desserts like their pecan pie. I recommend the Manhattan and Chef Special Omelettes for breakfast and the Club Sandwich.\\n\\n The food is half the reason you go there. The other half is just for the atmosphere. It has that old fashioned diner feel, and the wait staff is great, nice, and very entertaining.\\n\\nWhether you are really hungover or just looking for a great meal, you really can't go wrong going to Camellia.\", metadata={'source': './data/review_sample.csv', 'row': 377})],\n",
       " 'answer': \"The Camellia Grill is a legendary diner in New Orleans known for its old-fashioned atmosphere, friendly service, and delicious food. It features 100% low counter seating, where every seat faces the kitchen, giving it a classic diner feel. The menu includes a variety of breakfast options, burgers, shakes, and home-style cooking. It's crowded at peak breakfast and lunch times, and known for its quick and attentive service. The wait staff takes pride in their work, and the atmosphere is described as a fun, local establishment with a vintage feel. It's a popular spot for both locals and tourists, and is considered a NOLA classic.\"}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke(\n",
    "    {\n",
    "        \"messages\": demo_ephemeral_chat_history.messages,\n",
    "    }\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What can you tell me about the Camellia Grill?'),\n",
       "  AIMessage(content=\"The Camellia Grill is a legendary diner in New Orleans known for its old-fashioned atmosphere, friendly service, and delicious food. It features 100% low counter seating, where every seat faces the kitchen, giving it a classic diner feel. The menu includes a variety of breakfast options, burgers, shakes, and home-style cooking. It's crowded at peak breakfast and lunch times, and known for its quick and attentive service. The wait staff takes pride in their work, and the atmosphere is described as a fun, local establishment with a vintage feel. It's a popular spot for both locals and tourists, and is considered a NOLA classic.\"),\n",
       "  HumanMessage(content='tell me more about that!')],\n",
       " 'context': [Document(page_content='As we ate, we chatted and fist-bumped with various servers who came to check on us.  One offered free advice: \"It\\'s all in ya head,\" he said sagely, after we commented on the beautiful weather and atmosphere here.  \"Ya think positive, ya gonna live positive.\"  He continued this speech as a quasi-soliloquy as he went off in search of banana cream pie, and since the only piece left was a little thin, he cut us half a piece of coconut too.  They were both out of this world, and to this moment I regret every bite we left on our plates.\\n\\nYes, it\\'s just a diner.  And no, it\\'s not.  It\\'s so much more.', metadata={'source': './data/review_sample.csv', 'row': 248}),\n",
       "  Document(page_content=\": 738\\nreview_id: ctYtr59egY9tHgxjAuJyQw\\ntext: What can I say that hasn't already been said? The place is an institution and I've been going there since I was literally weeks old. Same as it's been for ages, you cram up to the counter when I get my chance, have a phenomenal omelet or waffle, and remember the goods time I've had, whether after a parade or for breakfast with family when I was 3-4, or after a drunken night out in my 20's.\", metadata={'source': './data/review_sample.csv', 'row': 738}),\n",
       "  Document(page_content=': 647\\nreview_id: 3nv3GLVtuCcWLbcmd6nS3w\\ntext: One of the main reasons I\\'m going back to New Orleans in October.  (the first being to remove a curse placed on me by a voodoo practicing street person whose parrot I inadvertently sang the wrong song to). \\n\\nLong story.\\n\\nOur waiter looked just like, and was every bit as cool as, Elvis Costello.  The Pecan Pie was so incredible I began to ask strangers if they were sure they were going to finish theirs.  All of their food is hardy and just makes you feel good.  The chili omelette - the thick, meaty burgers.  \"Warms the heart\" kinda food.  \\n\\nWe took a streetcar (named Desire?) from the far side of the French Quarter which allowed us to experience the beautiful Garden District in which the grill resides.  Definitely away from Bourbon Street tomfoolery, but well worth the sojourn.', metadata={'source': './data/review_sample.csv', 'row': 647}),\n",
       "  Document(page_content=': 551\\nreview_id: XWbICZmCbEeNwp2OaDaQqA\\ntext: Was here during Jazz Fest 2009.  This place is awesome!  Old style counter seating encourages neighborly conversations while excellent service provides entertainment and efficiency.  \"We\\'ll start with some waters\", I replied.  A server in white shirt and black bow tie exults in twang, \\'two glasses of Mississippi coming right up.\\'  Portions are huge!  I had a buttery burger melt that was juicy and hearty.  A traditional greasy spoon with the warmth of mama\\'s kitchen.  Once you walk in, you\\'re immediately part of the family. This home is where the heart is.', metadata={'source': './data/review_sample.csv', 'row': 551})],\n",
       " 'answer': \"The Camellia Grill has been an iconic fixture in New Orleans since the 1940s. It's famous for its authentic diner experience, complete with classic counter seating and a lively, friendly atmosphere. The staff is known for their entertaining banter and excellent service. The menu offers a wide range of comfort foods, including omelets, waffles, pecan pie, burgers, and hearty dishes that have been enjoyed by generations of patrons. The diner's charm and delicious food make it a must-visit spot for anyone looking to experience the essence of traditional New Orleans dining.\"}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_ai_message(response[\"answer\"])\n",
    "\n",
    "demo_ephemeral_chat_history.add_user_message(\"tell me more about that!\")\n",
    "\n",
    "retrieval_chain.invoke(\n",
    "    {\n",
    "        \"messages\": demo_ephemeral_chat_history.messages,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Camellia Grill is steeped in history and tradition, as it has been a beloved institution in New Orleans for decades. It's known for its retro decor and friendly, entertaining service. The diner's old-style counter seating encourages neighborly conversations, and the servers are known for their engaging personalities. The food is hearty and comforting, with generous portions. The diner has a welcoming atmosphere that makes patrons feel like they're part of the family. Overall, it's a must-visit spot for anyone looking to experience classic New Orleans dining and hospitality.\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define retrieval chain using a pipe directly into the document chain\n",
    "retrieval_chain_with_only_answer = (\n",
    "    RunnablePassthrough.assign(\n",
    "        context=parse_retriever_input | retriever,\n",
    "    )\n",
    "    | document_chain\n",
    ")\n",
    "\n",
    "retrieval_chain_with_only_answer.invoke(\n",
    "    {\n",
    "        \"messages\": demo_ephemeral_chat_history.messages,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\": 126\\nreview_id: ErIdqgbe_TVQuqCWuQQ3BQ\\ntext: This place is pretty straight forward. Breakfast and lunch dinner with animated old school wait staff. We usually come on a Saturday after soccer, if the line isn't around the building. Not sure what all the fuss is about, as Camellia Grill isn't the best breakfast stop, but it's decent. The biggest drawback for me is the seating. It's very crowded, and you will definitely be grazing knees or elbows with whomever is sitting next to you. It's fine for a quick bite with a person or two, but not a good place for groups.\", metadata={'source': './data/review_sample.csv', 'row': 126}),\n",
       " Document(page_content=\": 759\\nreview_id: NdZhVbRSBMXNQpuAKQXnBQ\\ntext: While this is definitely one of the more touristy restaurants in this part of town, Camellia Grill is consistently delicious and a frequent stop for me.\\n\\nIt has a true diner feel, using only a curved bar with stools rather than tables, which adds to a fun experience (but may present problems for people with disabilities, as the stools aren't particularly comfortable and can put strain on people's backs). The waiters behind the bar are very friendly and social. The food is always great, especially the burgers. I have never been disappointed with a meal here.\\n\\nThe only downside is that the restaurant smells a little funky sometimes, but it's not enough to ruin the experience.\", metadata={'source': './data/review_sample.csv', 'row': 759}),\n",
       " Document(page_content=': 926\\nreview_id: 71lCkEgQWf-evwZmEsaiIQ\\ntext: Wanting to venture out away from the unpleasant sights of downtown New Orleans for dinner, a cousin of mine recommended the Camellia Grill for dinner. So the family and I decided to take a little drive and check this place out. \\n\\nUpon walking in, you are greeted by a cashier that tells you to take a seat where you like. The setup is that of a diner with fixed barstools and you belly up to the counter. The family and I took our seats and were handed menus and a water. \\n\\nAfter making our decisions, the wife had red beans and rice; my youngest had a chocolate chip pancake; my oldest had chicken strips; and I had a bacon cheeseburger with fries. A lot of the stuff on the menu looked delicious. Since we were jerks, and came here 30 minutes before closing, I picked a cheeseburger quickly without thinking. \\n\\nIn good time our food started arriving piecemeal. The four of us started enjoying our meals promptly, so these folks could go home.', metadata={'source': './data/review_sample.csv', 'row': 926}),\n",
       " Document(page_content='On a great day, you\\'ll find the cooks to be more entertaining than anything else around.  I always think of Camellia Grill as \"dinner and a show\"... I\\'ve heard so many hilarious jokes (though not all of them were child-friendly) and seen spatula and egg juggling, tossing items on the grill from across the restaurant, and other such antics that keep me in stitches throughout my meal.\\n\\nThe only things keeping this from being a 5 star review are 1) the inevitably long wait, as there are few seats and no outdoor seating available, and 2) the prices are deceptively low on the menu... the burger is cheap, but they charge for it to be dressed, relatively high cost for a slice of cheese, fries are a la carte, so it can surprise you when you get your total.  Still a decent value, but I do wish I didn\\'t have to do so much math when ordering!  Worth every penny, though.', metadata={'source': './data/review_sample.csv', 'row': 539})]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Is the camellia grill kid-friendly?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='As we ate, we chatted and fist-bumped with various servers who came to check on us.  One offered free advice: \"It\\'s all in ya head,\" he said sagely, after we commented on the beautiful weather and atmosphere here.  \"Ya think positive, ya gonna live positive.\"  He continued this speech as a quasi-soliloquy as he went off in search of banana cream pie, and since the only piece left was a little thin, he cut us half a piece of coconut too.  They were both out of this world, and to this moment I regret every bite we left on our plates.\\n\\nYes, it\\'s just a diner.  And no, it\\'s not.  It\\'s so much more.', metadata={'source': './data/review_sample.csv', 'row': 248}),\n",
       " Document(page_content=\": 738\\nreview_id: ctYtr59egY9tHgxjAuJyQw\\ntext: What can I say that hasn't already been said? The place is an institution and I've been going there since I was literally weeks old. Same as it's been for ages, you cram up to the counter when I get my chance, have a phenomenal omelet or waffle, and remember the goods time I've had, whether after a parade or for breakfast with family when I was 3-4, or after a drunken night out in my 20's.\", metadata={'source': './data/review_sample.csv', 'row': 738}),\n",
       " Document(page_content=': 551\\nreview_id: XWbICZmCbEeNwp2OaDaQqA\\ntext: Was here during Jazz Fest 2009.  This place is awesome!  Old style counter seating encourages neighborly conversations while excellent service provides entertainment and efficiency.  \"We\\'ll start with some waters\", I replied.  A server in white shirt and black bow tie exults in twang, \\'two glasses of Mississippi coming right up.\\'  Portions are huge!  I had a buttery burger melt that was juicy and hearty.  A traditional greasy spoon with the warmth of mama\\'s kitchen.  Once you walk in, you\\'re immediately part of the family. This home is where the heart is.', metadata={'source': './data/review_sample.csv', 'row': 551}),\n",
       " Document(page_content='The crust is super thin, nearly like filo pastry, and the filling is the perfect blend of sweet, gooey goodness and pecans with just a hint of salt. The magic comes when they put it on the grill. Yes - they warm your pie (top down to start) on the grill, which is why it makes it even more important to order it a la mode. Some kind of awesome alchemy happens where the pie picks up just a hint of the delicious salty flavour of whatever has preceded it on the grill.\\n\\nIt was epic. I will hold the dessert memory dear until I can get back for another slice of heaven.', metadata={'source': './data/review_sample.csv', 'row': 550})]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Tell me more about that!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add query transformation step that removes references from the input\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "# We need a prompt that we can pass into an LLM to generate a transformed search query\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.2)\n",
    "\n",
    "query_transform_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation. Only respond with the query, nothing else.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "query_transforming_retriever_chain = RunnableBranch(\n",
    "    (\n",
    "        lambda x: len(x.get(\"messages\", [])) == 1,\n",
    "        # If only one message, then we just pass that message's content to retriever\n",
    "        (lambda x: x[\"messages\"][-1].content) | retriever,\n",
    "    ),\n",
    "    # If messages, then we pass inputs to LLM chain to transform the query, then pass to retriever\n",
    "    query_transform_prompt | chat | StrOutputParser() | retriever,\n",
    ").with_config(run_name=\"chat_retriever_chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate earlier chain with the new query_transforming_retriever_chain\n",
    "\n",
    "#restart chat history\n",
    "document_chain = create_stuff_documents_chain(chat, question_answering_prompt)\n",
    "\n",
    "conversational_retrieval_chain = RunnablePassthrough.assign(\n",
    "    context=query_transforming_retriever_chain,\n",
    ").assign(\n",
    "    answer=document_chain,\n",
    ")\n",
    "\n",
    "demo_ephemeral_chat_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what sort of food is Camellia Grill known for?'),\n",
       "  AIMessage(content='Camellia Grill is known for its delicious breakfast options such as eggs, bacon, grits, omelettes, and pancakes. They also offer a variety of burgers, sandwiches, shakes, and excellent desserts like pecan pie. The food is cooked right in front of you, and they offer classic American menu items with home-style cooking.')],\n",
       " 'context': [Document(page_content=\": 1026\\nreview_id: UuthR2CkatLYPnUVZMtaTw\\ntext: The Camellia Grill is a legend in New Orleans. Definitely the type of place I bring friends and family to when they come to visit. As locals, me and my family go there every time were in the area.  It's my favorite place to eat because the atmosphere, the service, and the food. When we walk in the door I feel like I'm stepping back in time to an old time diner.  The set-up is just one long counter surrounding the grills and it's decorated like were back in the 50's. The servers wear white dress shirts with bow ties like you expect to see in a diner. It has a vintage feel.  It's the time of place that the waiters call out your order to the back using diner lingo and they are always so friendly. If you don't know what to get they are always open to giving suggestions on classic favorites. They are perfect for late night, early morning, lunch, and dinner. They have breakfast food and a good variety of burgers and sandwiches. The food is cooked right in front of you, however you like it. I would recommend this place to locals and tourist. It's a new Orleans classic.\", metadata={'source': './data/review_sample.csv', 'row': 1026}),\n",
       "  Document(page_content=': 989\\nreview_id: PsWZU2dyIpWJZYxfgpqZMg\\ntext: The Camellia Grill is an institution, so much so that they were filming a segment for a TV show/movie on my recent visit (and the fascination surrounding this outweighed the delay in service that happened as a result).\\n\\nHere is what you will find...\\n\\n1. Servers like Michael who take a lot of pride in their work. They call out multiple orders at a time, then the cooks go to work.\\n2. 100% low counter seating. Every seat faces the kitchen. If your larger group wants to have a conversation, this may not be the best place.\\n3. Delicious breakfast options (standard eggs and bacon, grits, omelettes, pancakes), burgers, shakes, etc. Imagine taking the best of Waffle House and Johnny Rockets and putting it into a fun, local establishment.\\n4. It is crowded at peak breakfast and lunch times.', metadata={'source': './data/review_sample.csv', 'row': 989}),\n",
       "  Document(page_content=\": 377\\nreview_id: kR28I_muoQGwF4cO94Fwdw\\ntext: So much to say about Camellia Grill. It may seem like just an old, run-down restaurant, but it is much more than that. Camellia puts out great breakfast food that I will eat at any time of the day, very good burgers and sandwiches, and excellent desserts like their pecan pie. I recommend the Manhattan and Chef Special Omelettes for breakfast and the Club Sandwich.\\n\\n The food is half the reason you go there. The other half is just for the atmosphere. It has that old fashioned diner feel, and the wait staff is great, nice, and very entertaining.\\n\\nWhether you are really hungover or just looking for a great meal, you really can't go wrong going to Camellia.\", metadata={'source': './data/review_sample.csv', 'row': 377}),\n",
       "  Document(page_content=\": 720\\nreview_id: bd14Qo_l8VJh1-KfTmz7Fg\\ntext: Camellia Grill is the type of diners you see in the movies.  The atmosphere here is an overall good dining experience. I've been here twice, one for lunch and once for dinner. Countertop seating is where it's at here. There was no wait both times I've been there. Quick and attentive service has you in and out of there enjoying their delicious grill options and home-style cooking. Breakfast items are the classic American menu, with bacon, eggs, and more. The burgers were everything I would expect in a good burger. The patties had a nice taste and dressing options for the burger were plenty with fresh vegetables. The fries and onion rings were exceptional. This is a good place for chatting or even reading a book while eating, like I saw some people doing. The staff are familiar with the customers as well. Overall, Camelia's Grill delivers everything one would expect for a diner. This place is definitely a NOLA classic.\", metadata={'source': './data/review_sample.csv', 'row': 720})],\n",
       " 'answer': 'Camellia Grill is known for its delicious breakfast options such as eggs, bacon, grits, omelettes, and pancakes. They also offer a variety of burgers, sandwiches, shakes, and excellent desserts like pecan pie. The food is cooked right in front of you, and they offer classic American menu items with home-style cooking.'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke it\n",
    "demo_ephemeral_chat_history.add_user_message(\"what sort of food is Camellia Grill known for?\")\n",
    "\n",
    "response = conversational_retrieval_chain.invoke(\n",
    "    {\"messages\": demo_ephemeral_chat_history.messages},\n",
    ")\n",
    "\n",
    "demo_ephemeral_chat_history.add_ai_message(response[\"answer\"])\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what sort of food is Camellia Grill known for?'),\n",
       "  AIMessage(content='Camellia Grill is known for its delicious breakfast options such as eggs, bacon, grits, omelettes, and pancakes. They also offer a variety of burgers, sandwiches, shakes, and excellent desserts like pecan pie. The food is cooked right in front of you, and they offer classic American menu items with home-style cooking.'),\n",
       "  HumanMessage(content='tell me more about that!'),\n",
       "  AIMessage(content='Camellia Grill is known for its classic American diner fare, including breakfast items like eggs, bacon, and pancakes. They also serve up tasty burgers, sandwiches, and comforting home-style cooking. The diner has a cozy atmosphere with countertop seating and quick, attentive service. Customers often enjoy their delicious grill options, including burgers with a variety of fresh toppings, as well as classic American comfort food like chili cheese fries and apple pie. The staff are known for being friendly and welcoming, adding to the overall dining experience.')],\n",
       " 'context': [Document(page_content=\": 676\\nreview_id: Dt8XFSlvUv86m2tRlw6kmA\\ntext: Camellia Grill is the definition of a cute little diner with to-die-for food. You might be thrown off when you walk in, as it is a small space and viewing kitchen. But that opinion will go in their garbage when you sink into a pecan waffle, or slurp a chocolate freeze. And, if that wasn't enough, the customer service is BEYOND amazing.\", metadata={'source': './data/review_sample.csv', 'row': 676}),\n",
       "  Document(page_content=\": 910\\nreview_id: JPL3paT1M3U-r6dmF-9mEQ\\ntext: Didn't expect it but, The Camellia Grill was definitely cool. The prices are very moderate as well. Pretty much every menu item that we have purchased was really fresh and delicious. I became very good friends with the staff, who are all wonderful and super welcoming. The Camellia Grill, I love it so much.\", metadata={'source': './data/review_sample.csv', 'row': 910}),\n",
       "  Document(page_content=\": 720\\nreview_id: bd14Qo_l8VJh1-KfTmz7Fg\\ntext: Camellia Grill is the type of diners you see in the movies.  The atmosphere here is an overall good dining experience. I've been here twice, one for lunch and once for dinner. Countertop seating is where it's at here. There was no wait both times I've been there. Quick and attentive service has you in and out of there enjoying their delicious grill options and home-style cooking. Breakfast items are the classic American menu, with bacon, eggs, and more. The burgers were everything I would expect in a good burger. The patties had a nice taste and dressing options for the burger were plenty with fresh vegetables. The fries and onion rings were exceptional. This is a good place for chatting or even reading a book while eating, like I saw some people doing. The staff are familiar with the customers as well. Overall, Camelia's Grill delivers everything one would expect for a diner. This place is definitely a NOLA classic.\", metadata={'source': './data/review_sample.csv', 'row': 720}),\n",
       "  Document(page_content=': 423\\nreview_id: P9PEf3dyNcNTAOS9ptEN6g\\ntext: Camellia Grill is small place with good service and good comfort food. I would definitely recommend the cheeseburger, chili cheese fries and the apple pie. Our waiter Varnel (apologizes if i messed up the name) was very pleasant and recommended places to see in the area. Good price for the food as well.', metadata={'source': './data/review_sample.csv', 'row': 423})],\n",
       " 'answer': 'Camellia Grill is known for its classic American diner fare, including breakfast items like eggs, bacon, and pancakes. They also serve up tasty burgers, sandwiches, and comforting home-style cooking. The diner has a cozy atmosphere with countertop seating and quick, attentive service. Customers often enjoy their delicious grill options, including burgers with a variety of fresh toppings, as well as classic American comfort food like chili cheese fries and apple pie. The staff are known for being friendly and welcoming, adding to the overall dining experience.'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_user_message(\"tell me more about that!\")\n",
    "\n",
    "response = conversational_retrieval_chain.invoke(\n",
    "    {\"messages\": demo_ephemeral_chat_history.messages}\n",
    ")\n",
    "\n",
    "demo_ephemeral_chat_history.add_ai_message(response[\"answer\"])\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what sort of food is Camellia Grill known for?'),\n",
       "  AIMessage(content='Camellia Grill is known for its delicious breakfast options such as eggs, bacon, grits, omelettes, and pancakes. They also offer a variety of burgers, sandwiches, shakes, and excellent desserts like pecan pie. The food is cooked right in front of you, and they offer classic American menu items with home-style cooking.'),\n",
       "  HumanMessage(content='tell me more about that!'),\n",
       "  AIMessage(content='Camellia Grill is known for its classic American diner fare, including breakfast items like eggs, bacon, and pancakes. They also serve up tasty burgers, sandwiches, and comforting home-style cooking. The diner has a cozy atmosphere with countertop seating and quick, attentive service. Customers often enjoy their delicious grill options, including burgers with a variety of fresh toppings, as well as classic American comfort food like chili cheese fries and apple pie. The staff are known for being friendly and welcoming, adding to the overall dining experience.'),\n",
       "  HumanMessage(content='Is it known for anything else other than food?')],\n",
       " 'context': [Document(page_content=\": 720\\nreview_id: bd14Qo_l8VJh1-KfTmz7Fg\\ntext: Camellia Grill is the type of diners you see in the movies.  The atmosphere here is an overall good dining experience. I've been here twice, one for lunch and once for dinner. Countertop seating is where it's at here. There was no wait both times I've been there. Quick and attentive service has you in and out of there enjoying their delicious grill options and home-style cooking. Breakfast items are the classic American menu, with bacon, eggs, and more. The burgers were everything I would expect in a good burger. The patties had a nice taste and dressing options for the burger were plenty with fresh vegetables. The fries and onion rings were exceptional. This is a good place for chatting or even reading a book while eating, like I saw some people doing. The staff are familiar with the customers as well. Overall, Camelia's Grill delivers everything one would expect for a diner. This place is definitely a NOLA classic.\", metadata={'source': './data/review_sample.csv', 'row': 720}),\n",
       "  Document(page_content=': 1015\\nreview_id: lXySJxK3j0gipx_AjFQhmA\\ntext: Camellia Grill has a great atmosphere and an authentic New Orleans feel. It is a reactively small place, with diner style seating around a counter. The service is prompt and very friendly. The food is inexpensive, but not always amazing quality. They specialize in omelette sand breakfast choices. Their burgers are also very good. I would recommend getting either of those two options. This place is definitely worth checking out.', metadata={'source': './data/review_sample.csv', 'row': 1015}),\n",
       "  Document(page_content=\": 759\\nreview_id: NdZhVbRSBMXNQpuAKQXnBQ\\ntext: While this is definitely one of the more touristy restaurants in this part of town, Camellia Grill is consistently delicious and a frequent stop for me.\\n\\nIt has a true diner feel, using only a curved bar with stools rather than tables, which adds to a fun experience (but may present problems for people with disabilities, as the stools aren't particularly comfortable and can put strain on people's backs). The waiters behind the bar are very friendly and social. The food is always great, especially the burgers. I have never been disappointed with a meal here.\\n\\nThe only downside is that the restaurant smells a little funky sometimes, but it's not enough to ruin the experience.\", metadata={'source': './data/review_sample.csv', 'row': 759}),\n",
       "  Document(page_content=': 734\\nreview_id: V-5YCZ2mzuaTDk1TXacF5Q\\ntext: We had a great time at Camellia Grill!  The food was great! The people were wonderful!  We had great service! It was like stepping back in time!', metadata={'source': './data/review_sample.csv', 'row': 734})],\n",
       " 'answer': 'In addition to its delicious food, Camellia Grill is known for its nostalgic and authentic diner atmosphere. The diner has a classic American feel and is often described as a \"NOLA classic,\" offering a unique and memorable dining experience. The countertop seating and friendly service create a welcoming environment where customers can enjoy their meals. Some patrons have mentioned that it feels like stepping back in time, adding to the charm of the dining experience.'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_user_message(\"Is it known for anything else other than food?\")\n",
    "\n",
    "conversational_retrieval_chain.invoke(\n",
    "    {\"messages\": demo_ephemeral_chat_history.messages}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='When are the best times to come to the Camellia Grill?')],\n",
       " 'context': [Document(page_content=\": 1026\\nreview_id: UuthR2CkatLYPnUVZMtaTw\\ntext: The Camellia Grill is a legend in New Orleans. Definitely the type of place I bring friends and family to when they come to visit. As locals, me and my family go there every time were in the area.  It's my favorite place to eat because the atmosphere, the service, and the food. When we walk in the door I feel like I'm stepping back in time to an old time diner.  The set-up is just one long counter surrounding the grills and it's decorated like were back in the 50's. The servers wear white dress shirts with bow ties like you expect to see in a diner. It has a vintage feel.  It's the time of place that the waiters call out your order to the back using diner lingo and they are always so friendly. If you don't know what to get they are always open to giving suggestions on classic favorites. They are perfect for late night, early morning, lunch, and dinner. They have breakfast food and a good variety of burgers and sandwiches. The food is cooked right in front of you, however you like it. I would recommend this place to locals and tourist. It's a new Orleans classic.\", metadata={'source': './data/review_sample.csv', 'row': 1026}),\n",
       "  Document(page_content=\": 789\\nreview_id: 8IuGFYNrCYrXIrvN7Xy0HA\\ntext: It had been years since I've been to Camellia Grill so recently I made my way back there.  I was lucky that it was during the week so we did not have any wait time.  The hardest thing to do was put money in the parking meter.  I ordered the pancakes not a big omelet person.  It was a basic pancake nothing fancy but Camellia Grill is not fancy it's been around for a long time and walking in is like walking back in time the restaurant has not changed a bit including the counter service.  If you go in the summer on weekends be prepared to wait outside in the heat.  It's also a great late night place after a night of drinking in the city.\", metadata={'source': './data/review_sample.csv', 'row': 789}),\n",
       "  Document(page_content=\": 377\\nreview_id: kR28I_muoQGwF4cO94Fwdw\\ntext: So much to say about Camellia Grill. It may seem like just an old, run-down restaurant, but it is much more than that. Camellia puts out great breakfast food that I will eat at any time of the day, very good burgers and sandwiches, and excellent desserts like their pecan pie. I recommend the Manhattan and Chef Special Omelettes for breakfast and the Club Sandwich.\\n\\n The food is half the reason you go there. The other half is just for the atmosphere. It has that old fashioned diner feel, and the wait staff is great, nice, and very entertaining.\\n\\nWhether you are really hungover or just looking for a great meal, you really can't go wrong going to Camellia.\", metadata={'source': './data/review_sample.csv', 'row': 377}),\n",
       "  Document(page_content=': 989\\nreview_id: PsWZU2dyIpWJZYxfgpqZMg\\ntext: The Camellia Grill is an institution, so much so that they were filming a segment for a TV show/movie on my recent visit (and the fascination surrounding this outweighed the delay in service that happened as a result).\\n\\nHere is what you will find...\\n\\n1. Servers like Michael who take a lot of pride in their work. They call out multiple orders at a time, then the cooks go to work.\\n2. 100% low counter seating. Every seat faces the kitchen. If your larger group wants to have a conversation, this may not be the best place.\\n3. Delicious breakfast options (standard eggs and bacon, grits, omelettes, pancakes), burgers, shakes, etc. Imagine taking the best of Waffle House and Johnny Rockets and putting it into a fun, local establishment.\\n4. It is crowded at peak breakfast and lunch times.', metadata={'source': './data/review_sample.csv', 'row': 989})],\n",
       " 'answer': \"The best times to visit the Camellia Grill are during the week to avoid wait times, especially if you're not a fan of waiting in the heat. It's also mentioned that it's a great late-night place after a night of drinking in the city. Additionally, it's noted that it can be crowded at peak breakfast and lunch times, so visiting during off-peak hours may be more convenient.\"}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history = ChatMessageHistory()\n",
    "\n",
    "demo_ephemeral_chat_history.add_user_message(\"When are the best times to come to the Camellia Grill?\")\n",
    "\n",
    "conversational_retrieval_chain.invoke(\n",
    "    {\"messages\": demo_ephemeral_chat_history.messages}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Could not find: LangChain",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCamellia Grill is known for its classic diner-style food.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize LangChain\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m lc \u001b[38;5;241m=\u001b[39m \u001b[43mlangchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLangChain\u001b[49m()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Generate prompts/questions\u001b[39;00m\n\u001b[1;32m      8\u001b[0m prompts \u001b[38;5;241m=\u001b[39m lc\u001b[38;5;241m.\u001b[39mgenerate_questions(context, num_questions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain/__init__.py:388\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _llm_cache\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Could not find: LangChain"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "context = \"Camellia Grill is known for its classic diner-style food.\"\n",
    "\n",
    "# Initialize LangChain\n",
    "lc = langchain.LangChain()\n",
    "\n",
    "# Generate prompts/questions\n",
    "prompts = lc.generate_questions(context, num_questions=5)\n",
    "\n",
    "# Print the prompts/questions\n",
    "for i, prompt in enumerate(prompts, start=1):\n",
    "    print(f\"Prompt {i}: {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1: What is ?\n",
      "Prompt 2: What is ?\n",
      "Prompt 3: What is Camellia Grill is known for its classic diner-style food?\n",
      "Prompt 4: What is Camellia Grill is known for its classic diner-style food?\n",
      "Prompt 5: What is ?\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define a function to generate prompts/questions\n",
    "def generate_questions(context, num_questions=5):\n",
    "    # Split the context into sentences\n",
    "    sentences = context.split(\".\")\n",
    "    \n",
    "    # Initialize a list to store prompts/questions\n",
    "    prompts = []\n",
    "    \n",
    "    # Generate questions based on the context\n",
    "    for i in range(num_questions):\n",
    "        # Randomly select a sentence from the context\n",
    "        sentence = random.choice(sentences)\n",
    "        \n",
    "        # Create a prompt/question format\n",
    "        prompt = f\"What is {sentence.strip()}?\"\n",
    "        \n",
    "        # Append the prompt/question to the list\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    return prompts\n",
    "\n",
    "# Define the context\n",
    "context = \"Camellia Grill is known for its classic diner-style food.\"\n",
    "\n",
    "# Generate prompts/questions\n",
    "prompts = generate_questions(context, num_questions=5)\n",
    "\n",
    "# Print the prompts/questions\n",
    "for i, prompt in enumerate(prompts, start=1):\n",
    "    print(f\"Prompt {i}: {prompt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 48\u001b[0m\n\u001b[1;32m     40\u001b[0m     response \u001b[38;5;241m=\u001b[39m document_chain\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m     41\u001b[0m         {\n\u001b[1;32m     42\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: demo_ephemeral_chat_history\u001b[38;5;241m.\u001b[39mmessages,\n\u001b[1;32m     43\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: docs,\n\u001b[1;32m     44\u001b[0m         }\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# Add AI response to chat history\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     demo_ephemeral_chat_history\u001b[38;5;241m.\u001b[39madd_ai_message(\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Print the conversation history\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversation History:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "# Define a function to generate prompts/questions\n",
    "def generate_questions(context, num_questions=5):\n",
    "    # Split the context into sentences\n",
    "    sentences = context.split(\".\")\n",
    "    \n",
    "    # Initialize a list to store prompts/questions\n",
    "    prompts = []\n",
    "    \n",
    "    # Generate questions based on the context\n",
    "    for i in range(num_questions):\n",
    "        # Randomly select a sentence from the context\n",
    "        sentence = random.choice(sentences)\n",
    "        \n",
    "        # Create a prompt/question format\n",
    "        prompt = f\"What is {sentence.strip()}?\"\n",
    "        \n",
    "        # Append the prompt/question to the list\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    return prompts\n",
    "\n",
    "# Define the context\n",
    "context = \"Camellia Grill is known for its classic diner-style food.\"\n",
    "\n",
    "# Generate prompts/questions\n",
    "questions = generate_questions(context, num_questions=5)\n",
    "\n",
    "# Initialize ChatMessageHistory\n",
    "demo_ephemeral_chat_history = ChatMessageHistory()\n",
    "\n",
    "# Loop through the generated questions and invoke the document chain\n",
    "for question in questions:\n",
    "    # Add user message to chat history\n",
    "    demo_ephemeral_chat_history.add_user_message(question)\n",
    "    \n",
    "    # Invoke the document chain\n",
    "    response = document_chain.invoke(\n",
    "        {\n",
    "            \"messages\": demo_ephemeral_chat_history.messages,\n",
    "            \"context\": docs,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Add AI response to chat history\n",
    "    demo_ephemeral_chat_history.add_ai_message(response[\"answer\"])\n",
    "\n",
    "# Print the conversation history\n",
    "print(\"Conversation History:\")\n",
    "for message in demo_ephemeral_chat_history.messages:\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/tracypham/anaconda3/lib/python3.10/site-packages (0.1.16)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain) (0.0.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain) (2.6.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain) (0.1.44)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain) (0.1.38)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/tracypham/anaconda3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.document_chain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_chain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocumentChain\n\u001b[1;32m      2\u001b[0m document_chain \u001b[38;5;241m=\u001b[39m DocumentChain()  \u001b[38;5;66;03m# Initialize the DocumentChain object\u001b[39;00m\n\u001b[1;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m document_chain\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m      4\u001b[0m     {\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: demo_ephemeral_chat_history\u001b[38;5;241m.\u001b[39mmessages,\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: pandadata,\n\u001b[1;32m      7\u001b[0m     }\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.document_chain'"
     ]
    }
   ],
   "source": [
    "from langchain.document_chain import DocumentChain\n",
    "document_chain = DocumentChain()  # Initialize the DocumentChain object\n",
    "result = document_chain.invoke(\n",
    "    {\n",
    "        \"messages\": demo_ephemeral_chat_history.messages,\n",
    "        \"context\": pandadata,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Process the result as needed\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "tokenizers>=0.11.1,!=0.11.3,<0.14 is required for a normal functioning of this module, but found tokenizers==0.19.1.\nTry: pip install transformers -U or pip install -e '.[dev]' if you're working with git main",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2LMHeadModel, GPT2Tokenizer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load pre-trained GPT-2 model and tokenizer\u001b[39;00m\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m GPT2Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/__init__.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     33\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     logging,\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     48\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/dependency_versions_check.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tokenizers_available():\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# not required, check version only if installed\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[43mrequire_version_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeps\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, check dependency_versions_table.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/utils/versions.py:123\u001b[0m, in \u001b[0;36mrequire_version_core\u001b[0;34m(requirement)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m\"\"\"require_version wrapper which emits a core-specific hint on failure\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m hint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry: pip install transformers -U or pip install -e \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.[dev]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m if you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre working with git main\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequire_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequirement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/utils/versions.py:117\u001b[0m, in \u001b[0;36mrequire_version\u001b[0;34m(requirement, hint)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m want_ver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m op, want_ver \u001b[38;5;129;01min\u001b[39;00m wanted\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 117\u001b[0m         \u001b[43m_compare_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgot_ver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwant_ver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequirement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/utils/versions.py:50\u001b[0m, in \u001b[0;36m_compare_versions\u001b[0;34m(op, got_ver, want_ver, requirement, pkg, hint)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to compare versions for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: need=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwant_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgot_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is unusual. Consider\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m reinstalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops[op](version\u001b[38;5;241m.\u001b[39mparse(got_ver), version\u001b[38;5;241m.\u001b[39mparse(want_ver)):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is required for a normal functioning of this module, but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgot_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: tokenizers>=0.11.1,!=0.11.3,<0.14 is required for a normal functioning of this module, but found tokenizers==0.19.1.\nTry: pip install transformers -U or pip install -e '.[dev]' if you're working with git main"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Input question\n",
    "input_question = \"What can you tell me about the Camellia Grill?\"\n",
    "\n",
    "# Create a prompt template\n",
    "prompt_template = f\"Question: {input_question}\\nAnswer:\"\n",
    "\n",
    "# Tokenize the prompt\n",
    "input_ids = tokenizer.encode(prompt_template, return_tensors=\"pt\")\n",
    "\n",
    "# Generate questions based on the input question\n",
    "output = model.generate(input_ids, max_length=100, num_return_sequences=3, temperature=0.7, top_k=50)\n",
    "\n",
    "# Decode and print the generated questions\n",
    "for i, out in enumerate(output):\n",
    "    generated_question = tokenizer.decode(out, skip_special_tokens=True)\n",
    "    print(f\"Generated Question {i+1}: {generated_question}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement prompt-template (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for prompt-template\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install prompt-template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'input_variables'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the model (example, you can replace it with your own trained/fine-tuned model)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPromptTemplate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Input sentence\u001b[39;00m\n\u001b[1;32m      7\u001b[0m input_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Camellia Grill is a restaurant located in New Orleans.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/load/serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic/v1/main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic/v1/main.py:1100\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(model, input_data, cls)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1100\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1102\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/prompts/base.py:161\u001b[0m, in \u001b[0;36mBasePromptTemplate.validate_variable_names\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;129m@root_validator\u001b[39m()\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_variable_names\u001b[39m(\u001b[38;5;28mcls\u001b[39m, values: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate variable names do not include restricted names.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_variables\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    163\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have an input variable named \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, as it is used internally,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m please rename.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    165\u001b[0m         )\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input_variables'"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# Initialize the model (example, you can replace it with your own trained/fine-tuned model)\n",
    "model = PromptTemplate()\n",
    "\n",
    "# Input sentence\n",
    "input_sentence = \"The Camellia Grill is a restaurant located in New Orleans.\"\n",
    "\n",
    "# Generate questions based on the input sentence\n",
    "questions = model.generate_questions(input_sentence)\n",
    "\n",
    "# Print the generated questions\n",
    "for question in questions:\n",
    "    print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1: What do you think about the Camellia Grill?\n",
      "Prompt 2: How is the Camellia Grill?\n",
      "Prompt 3: Can you tell me more about the Camellia Grill?\n",
      "Prompt 4: How is the Camellia Grill?\n",
      "Prompt 5: What are your thoughts on the Camellia Grill?\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define a function to generate random questions\n",
    "def generate_questions(context, num_questions=5):\n",
    "    # Define a list of question templates\n",
    "    question_templates = [\n",
    "        \"Is the {context} good?\",\n",
    "        \"How is the {context}?\",\n",
    "        \"What do you think about the {context}?\",\n",
    "        \"Can you tell me more about the {context}?\",\n",
    "        \"Would you recommend the {context}?\",\n",
    "        \"What are your thoughts on the {context}?\",\n",
    "    ]\n",
    "    \n",
    "    # Initialize a list to store prompts/questions\n",
    "    prompts = []\n",
    "    \n",
    "    # Generate questions based on the context\n",
    "    for i in range(num_questions):\n",
    "        # Randomly select a question template\n",
    "        question_template = random.choice(question_templates)\n",
    "        \n",
    "        # Replace \"{context}\" with the actual context\n",
    "        prompt = question_template.format(context=context.strip())\n",
    "        \n",
    "        # Append the prompt/question to the list\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    return prompts\n",
    "\n",
    "# Define the context\n",
    "context = \"Camellia Grill\"\n",
    "\n",
    "# Generate prompts/questions\n",
    "prompts = generate_questions(context, num_questions=5)\n",
    "\n",
    "# Print the prompts/questions\n",
    "for i, prompt in enumerate(prompts, start=1):\n",
    "    print(f\"Prompt {i}: {prompt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
